{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from data_collection.parse_pcap import pcap_to_pandas, send_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we'll investigate whether a network eavesdropper can use device traffic to infer what people are doing inside their homes. We will pretend to be the eavesdropper and use a nearest neighbors classifier to perform this attack. We'll discuss what makes this algorithm effective, why this constitutes a privacy risk, and how we can protect device owners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Nearest neighbors is an AI algorithm that operates on a very simple premise: Objects of one type are more likely to be similar to other objects of the same type than to objects of any different type. Stated with a concrete example: \"Dogs are generally more similar to other dogs than they are to cats.\" \n",
    "\n",
    "This intuition translates naturally into a classification algorithm. If you have a labeled training set (objects with associated types) and you want to predict the label for a new object, find the $k$ objects in the training set that are most similar to the new object and predict the label of the majority of these $k$ closest objects. \n",
    "\n",
    "Consider the following graphical example with three classes of objects represented as 2D points colored by class. In this case, and for nearest neighbors in general, we consider \"most similar\" to mean \"closest,\" typically computed as the Euclidean distance between points. If you wanted to predict the class of the black stars using the closest point (1-nearest neighbor), what would be the predictions? How about if you used the 5 closest points (5-nearest neighbors)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of points\n",
    "points = np.array([(1, 8), (2.4, 5), (3,6), (2,4), (1.8, 7), (3, 3.7), (1, 5.5),\n",
    "                   (7,8), (9, 6), (10, 9), (6,10), (8,11), (8.2,9.5),\n",
    "                   (5,1), (6, 3), (6, 5.7), (4.5,5), (5.5,3.5), (6.7, 2), (3,4.2)])\n",
    "\n",
    "classes = np.array([0, 0, 0, 0, 0, 0, 0, \n",
    "                    1, 1, 1, 1, 1, 1, \n",
    "                    2, 2, 2, 2, 2, 2, 2])\n",
    "\n",
    "unknown = np.array([(3, 4.7), (8,8)])\n",
    "\n",
    "# plotting\n",
    "colors = ['red','green','blue']\n",
    "plt.scatter(*zip(*points), c=classes, cmap=mpl.colors.ListedColormap(colors))\n",
    "plt.plot(*zip(*unknown), '*', color='black', markersize=10)\n",
    "plt.xlim((-1,11))\n",
    "plt.ylim((-1,12))\n",
    "plt.grid(linestyle='--', alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This same technique generalizes to objects that have more features (higher dimensionality). It's hard to plot a 10 dimensional point, but the distance function works in arbitrarily high dimensions, so you can still find nearest neighbors. \n",
    "\n",
    "Let's try using the python Nearest Neighbors function with the above example points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training data in the right format\n",
    "\n",
    "# Create a nearest neighbors object\n",
    "k = ??\n",
    "nn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# train the classifier using the labeled points\n",
    "nn.fit(??, ??)\n",
    "\n",
    "# predict the value of the unknown points. \n",
    "predictions = nn.predict(??)\n",
    "\n",
    "# print the predictions\n",
    "print([colors[i] for i in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell above with different values of $k$ to check your answers from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to IoT Privacy\n",
    "\n",
    "In order to apply nearest neighbors to our IoT device network data we need to take the following steps:\n",
    "1. Convert the lists of packets into points, with each point encapsulating the device's network activity at a particular time \n",
    "2. Associate each point with a label (the activity you were doing with the device at the time of the point). \n",
    "3. Divide the points into a training set and a test set and train a K-Nearest Neighbors classifier. In reality, \"train\" is a bit of a misnomer for nearest neighbors classifiers, because all that happens is that the points get stored for comparision. No math actually takes place.\n",
    "4. Predict the labels of the test set using the classifier and calculate the accuracy of the predictions against the real labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import data and convert to points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcap = pcap_to_pandas('example_pcaps/nestcam_live.pcap') # this can take a few minutes\n",
    "pcap.head(n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is currently stored as a list of packets, but we want it as points corresponding to time periods. \n",
    "\n",
    "Let's clean up the data a bit first. First, let's filter out all packets not sent by the device. Second, let's assume that the attacker is outside the home and only has access to IP traffic. Third, let's assume that the attacker only has access to the time each packet was sent and its length (this is a reasonable assumption for encrypted traffic, as we will discuss). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only packets sent by device\n",
    "device_mac_address = ?? # device mac address as a string\n",
    "device_packets = pcap.loc[pcap[??] == device_mac_address] # column name (as string) to compare to device_mac_addresses\n",
    "\n",
    "# Remove all non-IP packets\n",
    "ip_packets = device_packets.loc[device_packets['ip_src'].notnull()]\n",
    "ip_packets = ip_packets.loc[ip_packets['ip_src'] != '0.0.0.0']\n",
    "ip_packets = ip_packets.loc[ip_packets['ip_dst'] != '0.0.0.0']\n",
    "\n",
    "# select only the 'time' and 'length' columns\n",
    "time_packets = ip_packets[['time', 'length']]\n",
    "time_packets.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, but why are the packet times just large numbers? These numbers are times in units of seconds since the \"epoch\" (January 1, 1970 at 00:00:00 GMT), a common format for computer timestamps. Let's convert them to normal-looking times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_packets[\"datetime\"] = [datetime.fromtimestamp(t) for t in time_packets['time']]\n",
    "time_packets.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert the list of packets into send rates by calculating the total amount of data sent (sum of packet lengths) during equal length time windows. The 'send_rates()' function is defined in parse_pcap.py which we imported at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_interval_sec = ??\n",
    "rates, rate_times = send_rates(time_packets, sampling_interval_sec)\n",
    "\n",
    "plt.plot(??, ??)\n",
    "plt.ylabel(\"Send Rate (bytes/sec)\")\n",
    "plt.xlabel(\"Time (sec)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try choosing different values for sampling_interval_sec and see how it affects the plots. What may be some benefits/drawbacks of having a small sampling interval? What may be benefits/drawbacks of having a large sampling interval? \n",
    "\n",
    "Next let's divide these rates into individual points we can associate with a specific activity by dividing the list of rates into longer time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function to divide send rates into larger chunks to act as points for kNN training\n",
    "def rates_to_points(rates, times, samples_per_point):\n",
    "    points = [rates[i:min(i+samples_per_point, rates.size-1)] for i in range(0, rates.size, samples_per_point)]\n",
    "    times = [times[i] for i in range(0, times.size, samples_per_point)]\n",
    "    return np.array(points[:-1]), np.array(times[:-1])\n",
    "    \n",
    "# number of send rate samples to include in each point. How many total seconds will each point represent? \n",
    "samples_per_point = ?? \n",
    "\n",
    "# perform the operation\n",
    "points, point_times = rates_to_points(??, ??, ??) \n",
    "\n",
    "# print the total number of points and an example\n",
    "print(??)\n",
    "print(??)\n",
    "\n",
    "# print the total number of point_times and an example\n",
    "print(??)\n",
    "print(??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew, now we have points and associated times. \n",
    "\n",
    "#### 2. Associate points with activity labels. \n",
    "\n",
    "First, read the labels from the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('example_pcaps/nestcam_live_labels.txt', header=None, names=[\"time\", \"activity\"])\n",
    "labels.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to associate the labels with the points based on the timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time column into a full date and time. Open pcap file in Wireshark to find the date it was recorded\n",
    "year = ??\n",
    "month = ??\n",
    "day = ??\n",
    "\n",
    "def convert_to_datetime(time):\n",
    "    hour_min_sec = time.split(\":\")\n",
    "    return datetime(year=year, month=month, day=day, \n",
    "                    hour=int(hour_min_sec[0]), minute=int(hour_min_sec[1]), second=int(hour_min_sec[2]))\n",
    "                        \n",
    "labels['datetime'] = labels['time'].apply(??)\n",
    "\n",
    "# convert datetime into a timestamp of seconds since epoch\n",
    "tzlocal = datetime.now().astimezone().tzinfo\n",
    "labels['timestamp'] = labels['datetime'].apply(lambda dt: dt.replace(tzinfo=tzlocal).timestamp())\n",
    "\n",
    "# Convert the activity names into class number labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels['class'] = label_encoder.fit_transform(labels[??]) # column name (as string) to convet to class numbers\n",
    "\n",
    "# print the first few rows of the resulting labels \n",
    "print(??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# finally, map the labels to the points \n",
    "point_labels = []\n",
    "label_row = 0\n",
    "\n",
    "for t in point_times:\n",
    "    # check if there are more activities\n",
    "    if label_row < labels.shape[0] - 1:\n",
    "        next_label_time = labels.iloc[label_row+1]['timestamp']\n",
    "        \n",
    "        # check if the next activity started before the current point\n",
    "        if t >= next_label_time:\n",
    "            label_row += 1\n",
    "            \n",
    "    # assign the current point to a class number\n",
    "    current_class = labels.iloc[label_row]['class']\n",
    "    point_labels.append(current_class)\n",
    "    \n",
    "# convert the result into a numpy array and print\n",
    "point_labels = np.array(point_labels)\n",
    "print(point_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew, now we have both labels and points. As is often the case with AI, data preprocessing turns out to be the hardest step in the process. Since our points have more than three dimensions, they are hard to visualize. Let's try to get a sense of them by plotting them in 2D using a transformation called \"Principle Component Analysis\" (which we will explain on the board). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to convert data to 2 dimensions\n",
    "\n",
    "pca = PCA(n_components=??) # n_components is number of dimensions of PCA result\n",
    "points_2d = pca.fit_transform(??)\n",
    "\n",
    "plt.scatter(*zip(*points_2d), c=point_labels, cmap=plt.get_cmap('Set1'), alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit messy, but when you collapse high dimensional data into 2D, much of the structure of the data is lost. \n",
    "Nevertheless what is your impression of the data? Are points of the same class closer to each other than to points of other classes? How well do you think that the nearest neighbors classifier will work? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Train k-nearest-neighbors classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the points into a training set and a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'test_size' parameter determines what fraction of the data is reserved for testing\n",
    "points_train, points_test, labels_train, labels_test = train_test_split(\n",
    "    points, point_labels, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the classifier on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a nearest neighbors object\n",
    "k = ??\n",
    "knn = KNeighborsClassifier(n_neighbors=??)\n",
    "\n",
    "# train the classifier using the labeled points\n",
    "knn.fit(??, ??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calculate accuracy on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the labels for the test set points using the trained classifier and compare the predicted labels to the actual labels. Refer to the [accuracy_score documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) to learn which arguments should be passed to 'accuracy_score()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the value of the test set points. \n",
    "labels_predictions = knn.predict(??)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(??,  ??)\n",
    "\n",
    "# print the predictions and the accuracy\n",
    "print(??)\n",
    "print(??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Questions\n",
    "\n",
    "#### 1. Why is this attack a privacy risk? \n",
    "\n",
    "#### 2. How could we (IoT device programmers, network operators, etc.) protect people from this attack?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Adjust parameters to improve accuracy.\n",
    "\n",
    "Now that we have a baseline accuracy, we can tweak the data preprocessing and classifier parameters to improve the accuracy. Look back through the code we've run so far. Which values have we set arbitrarily that could affect the results? Try changing these parameters and re-running the code to see how the classification accuracy is affected. Remember to re-run all of the cells below each change (or just restart the kernel and re-run all cells).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run on your data from last week\n",
    "\n",
    "Modify the notes you took about the activities you performed with your devices last week to match the format in  'example_pcaps/google_home_labels.txt'. Then try re-running the code above with your pcap file and labels file. You will likely need to change some of the parameters to optimize the results. How well does the k-NN algorithm do with your data? If the accuracy is worse than with the example data, think about why this might be the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Replace the KNearestClassifier above with a DecisionTreeClassifier _(advanced)_\n",
    "\n",
    "You discussed decision trees in lecture today. How well does a decision tree perform on this task compared to K-NN? Replace the nearest neighbors classifier in the code above with a decision tree classifier and compare accuracies. In order to do this, you'll need to reference the DecisionTreeClassifier documentation at [http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
